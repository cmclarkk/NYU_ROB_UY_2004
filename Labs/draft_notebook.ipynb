{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83313c37",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The goal of forward kinematics is to find out where the robot's feet are from the joint angles we read from the robot. You'll do this by implementing a `forward_kinematics(q)` that takes in the joint angles (12-D) and return four 4x4 transformation matrices that represnt the pose of the feed frame in the robot's body frame (look at `02_fk_implementation.ipynb`). Since implementing this function might take you some time, in this notebook we ask you to record some dataset from the real robot so you can use them back home to validate your work. Next week you will usa your `forward_kinematics(q)` to do some fun experiments with the real robot! \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5efce6c",
   "metadata": {},
   "source": [
    "# Dataset Recording \n",
    "\n",
    "## Robot Bridge\n",
    "\n",
    "If the robot bridge from the previous notebook is still running you can skip to the next step. Otherwise, follow the instructions in `00_interface_and_sim.ipynb` (\"Starting the Bridge\" section). \n",
    "\n",
    "## Connect to the Robot\n",
    "\n",
    "Like the previous notebook, you'll need to import the `RobotReal` and instantiate it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8b9248",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rob2004.interface import RobotReal\n",
    "robot_real = RobotReal(port=4243)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e83660b",
   "metadata": {},
   "source": [
    "Make sure you can read the robot states before continuing. Move the robot joints and run the next cell multiple times to make sure the values change as you move the legs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b848467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'q': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'dq': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'stamp': array(1.77051415e+09)}\n"
     ]
    }
   ],
   "source": [
    "state = robot_real.getJointState()\n",
    "print(state['q'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17075a9d",
   "metadata": {},
   "source": [
    "## Recording Datasets\n",
    "\n",
    "Here we ask you to record two sanity checking datasets and one as you desire.\n",
    "\n",
    "- **Linear Up-Down Motion**: For this dataset, you must lean the front foot against a vertical surface and gradually move the foot up and down along the world z-axis. You must make sure you minimize any non-vertical movements\n",
    "- **Touching Two Feet**: For this dataset, you start from a distance and gradually bring together the front right and back right feet unitl they touch. You repeat this multiple time such that the in one sequence, the feet make contact two or three times. \n",
    "- **You decide!(optional)**: You can come up with your own motion and record a dataset as you desire!\n",
    "\n",
    "Use the next cell to record the dataset (a list of joint angles every 100ms). You must record a video while collecting the data and include it in your report. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd8633e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "joint_angles = []\n",
    "start_time = time.time()\n",
    "while time.time() < 60:\n",
    "    state = robot_real.getJointState()\n",
    "    q = state['q'].copy().tolist()\n",
    "    joint_angles.append(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7eadb8",
   "metadata": {},
   "source": [
    "Make sure you save each dataset with its own distinctive name at the end of each recording:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d517e924",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "dataset_file_name = \"*.pkl\" # change the name for each dataset\n",
    "\n",
    "with open(dataset_file_name, 'wb') as f:\n",
    "    pickle.dump(joint_angles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccba0af",
   "metadata": {},
   "source": [
    "## Simulation Playback\n",
    "To make sure your data is recorded correctly, here you must use the simulator to playback the joint angles you saved in each dataset in the simulator. First run the simulator app in visualization model as explaned in the previous notebook and then connect to it here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c37712",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rob2004.interface import RobotSim\n",
    "robot_sim = RobotSim(port=4242)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d87c68",
   "metadata": {},
   "source": [
    "**Your Task**: Complete the `play_dataset` function and run it on all the datasets you recorded. You must share the screen recording of this playback and upload it alongside the video you recorded with your phone while collecting each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044cfb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_dataset(dataset_file, robot_sim):\n",
    "    with open(dataset_file, 'rb') as f:\n",
    "        joint_angles = pickle.load(f)\n",
    "    \n",
    "    # Todo: loop over the joint_anbles and send them to the simulator. Note that you must use time.sleep() with the same wait time as recording loop.\n",
    "    # Hint: for q in joint_angles:  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92b1c26",
   "metadata": {},
   "source": [
    "# Real Robot Bridge\n",
    "\n",
    "## Starting the Bridge \n",
    "Now that you have the simulator, let's see how we can control the real robot! If you remember, in the previous lab you had to launch several ros nodes. The procedure here is very similar. First SSH into the robot:\n",
    "\n",
    "```bash\n",
    "ssh pi@robot_ip # Get the IP address of the robot the same way you did in Lab1\n",
    "```\n",
    "\n",
    "When logged in, navigate to the rob2004 repository on the robot:\n",
    "\n",
    "```bash \n",
    "cd ~/rob2004\n",
    "ros2 launch scripts/robot.launch.py\n",
    "```\n",
    "with running above, the robot's joints should initialize like what you saw in the previous lab. Now open anohter terminal and SSH into the robot again:\n",
    "```bash\n",
    "ssh pi@robot_ip \n",
    "rob2004-robot-bridge --port 4243\n",
    "```\n",
    "If successful, the robot is now ready and waiting for you to connect to it with the `RobotReal` class!\n",
    "\n",
    "## Connecting to the Robot\n",
    "We interact with the robot through a Python class with the exact same interface as the simulated robot. This way you'll be able to run your algorithms in simulation and easity transfer to the real robot when you come to the lab! Import the interface class and instantiate it. You'll need the IP address of your robot (the same address you used to SSH into it) for this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b8a429",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rob2004.interface import RobotReal\n",
    "\n",
    "robot_ip=\"\" #Enter your robot's IP here\n",
    "robot_real = RobotReal(ip=robot_ip, port=4243)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6ac11c",
   "metadata": {},
   "source": [
    "If everything is done right, you should be able to read the robot's joint states exactly like before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8964698",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = robot_sim.getJointState()\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5a18eb",
   "metadata": {},
   "source": [
    "**Your Task**: Run the commands above repeatedly in a loop and see the joint values (`q`) changing as you move the robot's joints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76d427e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time  # Important: use time.sleep(0.1) to wait for 100 ms in between each update\n",
    "# ToDo: Write a loop to print the joint positions q for 100 times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca3f9e3",
   "metadata": {},
   "source": [
    "# Mirroring the Real Robot Movement In Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72e9e2d",
   "metadata": {},
   "source": [
    "Now that you have both the simulated and real robots running and can communicate with them (through `robot_sim` and `robot_real`), we can do a fun experiment. You can now write a similar loop to repeatedly show the latest status of the real robot in simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97652ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo: Complete this loop\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "while time.time()-start_time < 60:\n",
    "    q = None # Replace with the joint position from the real robot\n",
    "    # send the q above to the simulator\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d27689a",
   "metadata": {},
   "source": [
    "**Your Task**: Make a video of your success with this step and include in your report."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939cd203",
   "metadata": {},
   "source": [
    "# MuJoCo XML Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199e5cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rob2004.rerun import RerunVisualizer\n",
    "vis = visualizer = RerunVisualizer(app_name='logger', spawn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e49ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "info = ET.parse('/home/mim-server/projects/rooholla/NYU_ROB_UY_2004/rob2004/assets/robot/mujoco/pupper_v3_complete.position.fixed_base.xml')\n",
    "root = info.getroot()\n",
    "base = root.find('worldbody/body')\n",
    "chains = base.findall('body')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5aad5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.transform import Rotation as R\n",
    "def attrib2Pose(attrib):\n",
    "    if 'pos' in attrib:\n",
    "        link_pos = [float(n) for n in attrib['pos'].split(' ')] \n",
    "    else:\n",
    "        link_pos = [0, 0, 0]\n",
    "    if 'quat' in attrib:\n",
    "        link_quat = [float(n) for n in attrib['quat'].split(' ')] \n",
    "    else:\n",
    "        link_quat = [1, 0, 0 , 0]\n",
    "    link_quat = link_quat[1:]+[link_quat[0]]\n",
    "    link_R = R.from_quat(link_quat).as_matrix()\n",
    "    T = np.eye(4)\n",
    "    T[:3, :3] = link_R\n",
    "    T[:3, -1] = link_pos\n",
    "    return T\n",
    "\n",
    "def rq2Pose(r, q):\n",
    "    link_quat = q\n",
    "    link_quat = link_quat[1:]+[link_quat[0]]\n",
    "    link_R = R.from_quat(link_quat).as_matrix()\n",
    "    T = np.eye(4)\n",
    "    T[:3, :3] = link_R\n",
    "    T[:3, -1] = r\n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a51b46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kinematic_at_rest = {}\n",
    "for n in range(4):\n",
    "    attrib = base.findall('body')[n].attrib\n",
    "    name = attrib['name']\n",
    "    B0_T_B1 = attrib2Pose(attrib)\n",
    "    attrib = base.findall('body')[n].findall('body')[0].attrib\n",
    "    B1_T_B2 = attrib2Pose(attrib)\n",
    "    attrib = base.findall('body')[n].findall('body')[0].findall('body')[0].attrib\n",
    "    B2_T_B3 = attrib2Pose(attrib)\n",
    "    \n",
    "    attrib = base.findall('body')[n].findall('body')[0].findall('body')[0].findall('site')[0].attrib\n",
    "    B3_T_Foot = attrib2Pose(attrib)\n",
    "\n",
    "    kinematic_at_rest[name] = dict(\n",
    "        B0_T_B1=B0_T_B1,\n",
    "        B1_T_B2=B1_T_B2,\n",
    "        B2_T_B3 = B2_T_B3,\n",
    "        B3_T_Foot = B3_T_Foot,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7674e1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwardKinematics(chain):\n",
    "    B0_T_B1 = chain['B0_T_B1']\n",
    "    B1_T_B2 = chain['B1_T_B2']\n",
    "    B2_T_B3 = chain['B2_T_B3']\n",
    "    B0_T_B2 = B0_T_B1@B1_T_B2\n",
    "    B0_T_B3 = B0_T_B2@B2_T_B3\n",
    "    B0_T_Foot = B0_T_B3@chain['B3_T_Foot']\n",
    "    return dict(\n",
    "        B0_T_B1 = B0_T_B1,\n",
    "        B0_T_B2 = B0_T_B2, \n",
    "        B0_T_B3 = B0_T_B3,\n",
    "        B0_T_Foot = B0_T_Foot\n",
    "    )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d005e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "T_offset = np.eye(4)\n",
    "rot = R.from_euler('x', -90, degrees=True).as_matrix()\n",
    "rot2 = R.from_euler('z', 90, degrees=True).as_matrix()\n",
    "T_offset[:3, :3] = rot2@rot\n",
    "\n",
    "vis.logMeshFile(\"/home/mim-server/projects/rooholla/NYU_ROB_UY_2004/rob2004/assets/robot/meshes/dae/Body V4 v70.001.dae\",\n",
    "                T_offset, 'robot/base', alpha=0)\n",
    "\n",
    "fk = forwardKinematics(kinematic_at_rest['leg_front_r_1'])\n",
    "B0_T_B1 = fk['B0_T_B1']\n",
    "B1_T_mesh = rq2Pose([0, 0, -0.028], [1.32679e-06, 0, 0, 1])\n",
    "B0_T_mesh = B0_T_B1@B1_T_mesh\n",
    "vis.logMeshFile(\"/home/mim-server/projects/rooholla/NYU_ROB_UY_2004/rob2004/assets/robot/meshes/dae/Leg Assembly For Flanged v26.010.dae\",\n",
    "                B0_T_mesh, 'robot/leg_front_l_1')\n",
    "\n",
    "B0_T_B2 = fk['B0_T_B2']\n",
    "B2_T_mesh = rq2Pose([-0.028, 0, 0],[-2.93388e-06, 0.707108, 2.26082e-06, 0.707106])\n",
    "B0_T_mesh = B0_T_B2@B2_T_mesh\n",
    "vis.logMeshFile(\"/home/mim-server/projects/rooholla/NYU_ROB_UY_2004/rob2004/assets/robot/meshes/dae/Leg Assembly For Flanged v26.006.dae\",\n",
    "                B0_T_mesh, 'robot/leg_front_l_2')\n",
    "\n",
    "B0_T_B3 = fk['B0_T_B3']\n",
    "B2_T_mesh = rq2Pose([0.0685, 0.0494, -0.028],[1.32679e-06, 0, 0, 1])\n",
    "B0_T_mesh = B0_T_B3@B2_T_mesh\n",
    "vis.logMeshFile(\"/home/mim-server/projects/rooholla/NYU_ROB_UY_2004/rob2004/assets/robot/meshes/dae/Leg Assembly For Flanged v26.007.dae\",\n",
    "                B0_T_mesh, 'robot/leg_front_l_3')\n",
    "\n",
    "\n",
    "import time\n",
    "vis.logCoordinateFrame(np.eye(4), f'world/0', axis_length=0.05)\n",
    "\n",
    "for name in kinematic_at_rest:\n",
    "    if name=='leg_front_r_1':\n",
    "        chain = kinematic_at_rest[name]\n",
    "        result = forwardKinematics(chain)\n",
    "        for k, T in enumerate(result.values()):\n",
    "            time.sleep(0.5)\n",
    "            vis.logCoordinateFrame(T, f'world/{name}/{k}', axis_length=0.05)\n",
    "    \n",
    "            \n",
    "time.sleep(0.5)\n",
    "vis.logCoordinateFrame(T, f'world/{name}/{k}', axis_length=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef94399d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rob2004",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
